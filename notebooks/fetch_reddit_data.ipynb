{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import zipfile\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sqlite_to_temp(zip_path, sqlite_filename, temp_dir=\"Data/Temp\"):\n",
    "    import os\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    temp_file_path = os.path.join(temp_dir, \"temp_extracted.sqlite\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        with z.open(sqlite_filename) as zipped_db:\n",
    "            with open(temp_file_path, 'wb') as out_file:\n",
    "                for chunk in iter(lambda: zipped_db.read(1024 * 1024), b''):\n",
    "                    out_file.write(chunk)\n",
    "\n",
    "    return temp_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd691bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sqlite_table_names(sqlite_path):\n",
    "    conn = sqlite3.connect(sqlite_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [t[0] for t in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sqlite_chunk(conn, table_name, chunk_size, offset):\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT {chunk_size} OFFSET {offset}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_chunk_to_csv(df, output_folder, part_num):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, f\"reddit_comments_part_{part_num}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved chunk {part_num} with {len(df)} rows ‚Üí {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13265294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks_to_csv(zip_path, sqlite_filename, table_name, total_rows, chunk_size, output_folder):\n",
    "    sqlite_path = extract_sqlite_to_temp(zip_path, sqlite_filename)\n",
    "    print(f\"üìÅ Temp SQLite file created at: {sqlite_path}\")\n",
    "\n",
    "    conn = sqlite3.connect(sqlite_path)\n",
    "\n",
    "    offset = 0\n",
    "    part = 1\n",
    "    while offset < total_rows:\n",
    "        df = fetch_sqlite_chunk(conn, table_name, chunk_size, offset)\n",
    "        write_chunk_to_csv(df, output_folder, part)\n",
    "        offset += chunk_size\n",
    "        part += 1\n",
    "\n",
    "    conn.close()\n",
    "    os.remove(sqlite_path)\n",
    "    print(\"üßπ Temp file deleted. Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21146754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Main script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    ZIP_PATH = \"D:/Portfolio/reddit-analytics-pipeline/data/raw/reddit-comments-may-2015.zip\"\n",
    "    SQLITE_FILENAME = \"database.sqlite\"\n",
    "    OUTPUT_FOLDER = \"Data/Partitions\"\n",
    "\n",
    "    # Step 1: Extract to temp and inspect table names\n",
    "    temp_sqlite_path = extract_sqlite_to_temp(ZIP_PATH, SQLITE_FILENAME)\n",
    "    print(temp_sqlite_path)\n",
    "    table_names = get_sqlite_table_names(temp_sqlite_path)\n",
    "    print(\"üìã Tables inside database:\", table_names)\n",
    "    \n",
    "      # OPTIONAL: Pause here if you want to inspect table names before continuing\n",
    "    # Example: Comment out below line until you're ready\n",
    "    extract_chunks_to_csv(\n",
    "        zip_path=ZIP_PATH,\n",
    "        sqlite_filename=SQLITE_FILENAME,\n",
    "        table_name=\"May2015\",  # Replace with selected table\n",
    "        total_rows=250000,\n",
    "        chunk_size=50000,\n",
    "        output_folder=OUTPUT_FOLDER\n",
    "    )\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fed27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
